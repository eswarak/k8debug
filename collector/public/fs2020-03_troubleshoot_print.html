<br><p>All references to &#60;team&#62; should be replaced with your team name.</p><p>This lab is intended to get the student familar with creating a pod in the team project.  There is no problem to be researched or diagnosis to be performed.  </p><p>This lab demonstrates how to deploy a pod.</p><h4 id="resources">Resources</h4><ul><li>K8 yaml - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/house.yaml" target="_blank">house.yaml</a></li><li>Dockerfile - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/house_Dockerfile" target="_blank">Dockerfile</a></li></ul><h4 id="useful-information">Useful information</h4><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Item</th><th align="left">Value</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">cpu:</td><td align="left">50m</td></tr><tr style="background-color: #f8f8f8;"><td align="left">memory:</td><td align="left">50Mi</td></tr><tr style="background-color: #f8f8f8;"><td align="left">image:</td><td align="left">ibmicpcoc/house:latest</td></tr><tr style="background-color: #f8f8f8;"><td align="left">ports</td><td align="left">none</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Docker</td><td align="left">CMD [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;./house.sh&quot;]</td></tr></tbody></table><br><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Task description</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">Download the resource K8 yaml file.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Edit and save the file after replacing all references of <strong>&#60;team&#62;</strong> with your team name.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Create the K8 objects using oc create</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Did the pod deploy successfully?  If not, correct the issue and re-create the K8 objects.</td></tr></tbody></table><hr><br><p>To create the pod use the command: <strong>oc create -f &#60;file&#62;;</strong>   (replace &#60;file&#62; with the name of the yaml file you have saved and edited.)</p><hr><h4 id="diagnosis">Diagnosis</h4><p>No diagnosis is necessary for this lab.  A new pod should be created after editing the yaml file and using the oc create command.</p><h4 id="problem-discovered">Problem discovered</h4><p>N/A</p><h4 id="resolution">Resolution</h4><p>Edit the house.yaml file and modify all references of &#60;team&#62; to your team name.</p><br><pre><code><br>--- #<br>--- # Course :: Problem Diagnosis and Troubleshooting Lab <br>--- <br>apiVersion: apps/v1<br>kind: Deployment<br>metadata:<br>  name: &lt;team&gt;-house<br>  namespace: &lt;team&gt;<br>  labels:<br>    app: &lt;team&gt;-house<br>spec:<br>  selector:<br>    matchLabels:<br>      app: &lt;team&gt;-house<br>  replicas: 1<br>  template:<br>    metadata:<br>      labels:<br>        app: &lt;team&gt;-house<br>    spec:<br>      containers:<br>      - name: &lt;team&gt;-house<br>        image: docker.io/ibmicpcoc/house:latest<br>        imagePullPolicy: Always<br>        env:<br>          - name: APP_NAMESPACE<br>            valueFrom:<br>              fieldRef:<br>                fieldPath: metadata.namespace<br>          - name: APP_NAME<br>            valueFrom:<br>              fieldRef:<br>                fieldPath: metadata.name<br>          - name: COLLECTOR_CONFIG<br>            valueFrom: <br>              configMapKeyRef:<br>                name: &lt;team&gt;-collector-config<br>                key: COLLECTOR_CONFIG<br>          - name: INSTRUCTOR_CONFIG<br>            valueFrom: <br>              configMapKeyRef:<br>                name: &lt;team&gt;-collector-config<br>                key: INSTRUCTOR_CONFIG<br>        resources:<br>          requests:<br>            cpu: 50m<br>            memory: 50Mi<br>---<br></code></pre><br><p>Saved the modified file.</p><br><br><p>Create the pod with the modified &quot;house.yaml&quot; file.</p><br><pre><code><br>-- Create --<br><br>Command: <br><br>    oc create -f house.yaml<br><br><br>Example output:<br><br>    deployment.apps/house created<br></code></pre><br><p>Verify the pod deployed successfully.</p><br><br><pre><code><br>-- Get --<br><br>Command:<br><br>    oc get pods -n &lt;team&gt;          # change &lt;team&gt; to your team project<br><br><br>Example output:<br><br>    NAME                                 READY     STATUS    RESTARTS   AGE<br>    team10-house-85976f7b7d-hprtg        1/1       Running   0          3h<br><br>    . . .  portions of output removed<br></code></pre><br><hr><br><hr><br><p>All references to &#60;team&#62; should be replaced with your team name.</p><h4 id="resources-1">Resources</h4><ul><li>K8 yaml    - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/carbs.yaml" target="_blank">carbs.yaml</a>  </li><li>Dockerfile - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/carbs_Dockerfile" target="_blank">Dockerfile</a>  </li></ul><h4 id="useful-information-1">Useful information</h4><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Item</th><th align="left">Value</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">spec.template.spec.containers[*].resouces.request.cpu</td><td align="left">100m</td></tr><tr style="background-color: #f8f8f8;"><td align="left">spec.template.spec.containers[*].resouces.request.memory:</td><td align="left">100Mi</td></tr><tr style="background-color: #f8f8f8;"><td align="left">spec.template.spec.containers[*].image:</td><td align="left">ibmicpcoc/carbs:latest</td></tr><tr style="background-color: #f8f8f8;"><td align="left">spec.template.spec.containers[*].ports</td><td align="left">none</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Docker CMD</td><td align="left">[&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;./carbs.sh&quot;]</td></tr></tbody></table><br><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Task description</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">Within your team project diagnose the pod that begins with <strong>&#60;team&#62; -carbs</strong></td></tr><tr style="background-color: #f8f8f8;"><td align="left">Download the resource K8 yaml file.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Edit and save the file after replacing all references of &#60;team&#62; with your team name.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Create the K8 objects.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Did the pod deploy successfully?  If not, correct the issue and re-create the K8 objects.</td></tr></tbody></table><hr><br><ul><li><p>Describe the pod.</p></li><li><p>You can get all events from the namespace by using, oc get events -n <strong>&#60;team&#62;</strong></p></li><li><p>A single cpu is defined with 1000m. The container cpu resources should use <strong>1/10</strong> of a cpu.  </p></li><li><p>Editing a running pod is another method to change the pod.  Use the command:</p></li></ul><br><pre><code>OC_EDITOR=&quot;nano&quot; oc edit deployment/&lt;team&gt;-carbs   &lt;&lt;&lt;--- replace &lt;team&gt; with team name  </code></pre><p>Nano is the editor defined in the above command.  By removing the OC_EDITOR=&quot;nano&quot; parameter the default editor on your machine will be opened.</p><hr><h4 id="diagnosis-1">Diagnosis</h4><p>When attempting to deploy the pod the yaml file is not properly defined.</p><p>Check the Pod status</p><br><pre><code><br>-- Get --<br><br>Command:<br><br>    oc get pods <br><br><br>Example output:<br><br>    NAME                              READY     STATUS    RESTARTS   AGE<br>    team01-carbs-5c96bc649-tjnhb       0/1       Pending   0          2m</code></pre><br><p>Describe the pod</p><br><br><pre><code><br>-- Describe --<br><br>Command:<br><br>    oc describe po team01-carbs-5c96bc649-tjnhb<br><br><br>Example output:    <br><br>    Name:               team01-carbs-5c96bc649-tjnhb<br>    Namespace:          team01<br>    Priority:           0<br>    PriorityClassName:  &lt;none&gt;<br>    Node:               &lt;none&gt;<br>    Labels:             app=team01-carbs<br>                        pod-template-hash=175267205<br>    Annotations:        kubernetes.io/psp=ibm-privileged-psp<br>    Status:             Pending<br>    IP:<br>    Controlled By:      ReplicaSet/team01-carbs-5c96bc649<br>    Containers:<br>      team01-carbs:<br>        Image:      ibmicpcoc/carbs:latest<br>        Port:       &lt;none&gt;<br>        Host Port:  &lt;none&gt;<br>        Requests:<br>          cpu:     25<br>          memory:  100Mi<br>        Environment:<br>          APP_NAMESPACE:      team01 (v1:metadata.namespace)<br>          APP_NAME:           team01-carbs-5c96bc649-tjnhb (v1:metadata.name)<br>          COLLECTOR_CONFIG:   &lt;set to the key &#39;COLLECTOR_CONFIG&#39; of config map &#39;team01-collector-config&#39;&gt;   Optional: false<br>          INSTRUCTOR_CONFIG:  &lt;set to the key &#39;INSTRUCTOR_CONFIG&#39; of config map &#39;team01-collector-config&#39;&gt;  Optional: false<br>        Mounts:<br>          /var/run/secrets/kubernetes.io/serviceaccount from default-token-mq64m (ro)<br>    Conditions:<br>      Type           Status<br>      PodScheduled   False<br>    Volumes:<br>      default-token-mq64m:<br>        Type:        Secret (a volume populated by a Secret)<br>        SecretName:  default-token-mq64m<br>        Optional:    false<br>    QoS Class:       Burstable<br>    Node-Selectors:  &lt;none&gt;<br>    Tolerations:     node.kubernetes.io/memory-pressure:NoSchedule<br>                     node.kubernetes.io/not-ready:NoExecute for 300s<br>                     node.kubernetes.io/unreachable:NoExecute for 300s<br>    Events:<br>      Type     Reason            Age                 From               Message<br>      ----     ------            ----                ----               -------<br>      Warning  FailedScheduling  58s (x121 over 5m)  default-scheduler  0/3 nodes are available: 3 Insufficient cpu.</code></pre><br><p>In the &quot;Events&quot; section review the &quot;Message&quot; from the entry with &quot;Type&quot; Warning and &quot;Reason&quot; FailedScheduling</p><br><br><pre><code>    0/3 nodes are available: 3 Insufficient cpu.</code></pre><br><br><br><p>Example of Get Events in namespace</p><br><pre><code><br>-- Get Events --<br><br>Command:<br><br>    oc get events -n &lt;team&gt;<br><br><br>Example output:<br><br>    LAST SEEN   FIRST SEEN   COUNT     NAME                                            KIND         SUBOBJECT                      TYPE      REASON              SOURCE                    MESSAGE<br>    7m          7m           1         team01-carbs.157be1efb7ad1a77                    Deployment                                  Normal    ScalingReplicaSet   deployment-controller     Scaled up replica set team01-carbs-5c96bc649 to 1<br>    7m          7m           1         team01-carbs-5c96bc649.157be1efb85494ba          ReplicaSet                                  Normal    SuccessfulCreate    replicaset-controller     Created pod: team01-carbs-5c96bc649-tjnhb<br>    2m          7m           121       team01-carbs-5c96bc649-tjnhb.157be1efb858b4b3    Pod                                         Warning   FailedScheduling    default-scheduler         0/4 nodes are available: 4 Insufficient cpu.<br><br></code></pre><br><br><br><h4 id="problem-discovered-1">Problem discovered</h4><p>Events output indicates the pod is FailedScheduling because there are not enough CPU resources available.</p><br><h4 id="resolution-1">Resolution</h4><p>Multiple methods exist to correct the issue, below are two options. </p><blockquote><p>The first method is deleting the old pod, edit the yaml file, and re-create the pod.  </p></blockquote><p>Edit the carbs.yaml file and modify <i>cpu</i> to decrease the amount of cpu to 10% of a single CPU.</p><p>Delete the running pod.</p><br><pre><code><br>-- Delete --<br><br>Command:  <br><br>    oc delete -f carbs.yaml<br><br>Example output:<br><br>    deployment.apps &quot;carbs&quot; deleted<br></code></pre><br><br><br><p>Example of the edited file carbs.yaml (only a portion of file shown below)</p><br><pre><code><br>    spec:<br>      selector:<br>        matchLabels:<br>         app: &lt;team&gt;-carbs<br>     replicas: 1<br>     template:<br>       metadata:<br>         labels:<br>           app: &lt;team&gt;-carbs<br>       spec:<br>         containers:<br>         - name: &lt;team&gt;-carbs<br>           image: ibmicpcoc/carbs:latest<br>           resources:<br>             requests:<br>               cpu: 25000m                   &lt;=== change value to 100m<br>               memory: 100Mi</code></pre><br><br><br><p>Create the deployment using the modified <strong>carbs.yaml</strong> file.</p><br><pre><code><br>-- Create --<br><br>Command:<br><br>    oc create -f carbs.yaml<br><br><br>Example output:<br><br>    deployment.apps/&lt;team&gt;-carbs created.   &lt;&lt;&lt;--- &lt;team&gt; will be replaced with team name<br><br></code></pre><br><br><br><blockquote><p>The second method shown is editing the running pod.  </p></blockquote><p>Edit the running pod.  The kubernetes object content is available in the editor (shown below).  Note the content has both the spec: and status: sections. </p><p>Locate the line cpu: &quot;25&quot; and change the line to cpu: 100m (without quotes)</p><br><pre><code><br>-- Edit --<br><br>Command:  <br><br>    OC_EDITOR=&quot;nano&quot; oc edit deployment/&lt;team&gt;-carbs     # replace &lt;team&gt; <br><br>Content shown when editor is open.  The team01-carbs deployment is being shown:<br><br># Please edit the object below. Lines beginning with a &#39;#&#39; will be ignored,<br># and an empty file will abort the edit. If an error occurs while saving this file will be<br># reopened with the relevant failures.<br>#<br>apiVersion: extensions/v1beta1<br>kind: Deployment<br>metadata:<br>  annotations:<br>    deployment.kubernetes.io/revision: &quot;1&quot;<br>  creationTimestamp: 2019-01-21T14:01:56Z<br>  generation: 1<br>  labels:<br>    app: team01-carbs<br>  name: team01-carbs<br>  namespace: team01<br>  resourceVersion: &quot;5834141&quot;<br>  selfLink: /apis/extensions/v1beta1/namespaces/team01/deployments/team01-carbs<br>  uid: 1d02fbe9-1d85-11e9-b012-06ed6a534df5<br>spec:<br>  progressDeadlineSeconds: 600<br>  replicas: 1<br>  revisionHistoryLimit: 10<br>  selector:<br>    matchLabels:<br>      app: team01-carbs<br>  strategy:<br>    rollingUpdate:<br>      maxSurge: 25%<br>      maxUnavailable: 25%<br>    type: RollingUpdate<br>  template:<br>    metadata:<br>      creationTimestamp: null<br>      labels:<br>        app: team01-carbs<br>    spec:<br>      containers:<br>      - env:<br>        - name: APP_NAMESPACE<br>          valueFrom:<br>            fieldRef:<br>              apiVersion: v1<br>              fieldPath: metadata.namespace<br>        - name: APP_NAME<br>          valueFrom:<br>            fieldRef:<br>              apiVersion: v1<br>              fieldPath: metadata.name<br>        - name: COLLECTOR_CONFIG<br>          valueFrom:<br>            configMapKeyRef:<br>              key: COLLECTOR_CONFIG<br>              name: team01-collector-config<br>        - name: INSTRUCTOR_CONFIG<br>          valueFrom:<br>            configMapKeyRef:<br>              key: INSTRUCTOR_CONFIG<br>              name: team01-collector-config<br>        image: ibmicpcoc/carbs:latest<br>        imagePullPolicy: Always<br>        name: team01-carbs<br>        resources:<br>          requests:<br>            cpu: &quot;25&quot;                         &lt;=== change value to 100m without quotes<br>            memory: 100Mi<br>        terminationMessagePath: /dev/termination-log<br>        terminationMessagePolicy: File<br>      dnsPolicy: ClusterFirst<br>      restartPolicy: Always<br>      schedulerName: default-scheduler<br>      securityContext: {}<br>      terminationGracePeriodSeconds: 30<br>status:<br>  conditions:<br>  - lastTransitionTime: 2019-01-21T14:01:56Z<br>    lastUpdateTime: 2019-01-21T14:01:56Z<br>    message: Deployment does not have minimum availability.<br>    reason: MinimumReplicasUnavailable<br>    status: &quot;False&quot;<br>    type: Available<br>  - lastTransitionTime: 2019-01-21T14:11:57Z<br>    lastUpdateTime: 2019-01-21T14:11:57Z<br>    message: ReplicaSet &quot;team01-carbs-5c96bc649&quot; has timed out progressing.<br>    reason: ProgressDeadlineExceeded<br>    status: &quot;False&quot;<br>    type: Progressing<br>  observedGeneration: 1<br>  replicas: 1    <br><br><br>NOTE: You must save the file for the changes to take effect.<br><br><br><br>Example output:<br>    deployment.extensions/team01-carbs edited<br></code></pre><br><p>Did this resolve the issue?</p><br><br><pre><code><br>-- Get --<br><br>Command: <br><br>    oc get pods<br><br><br>Example output:<br><br>    NAME                              READY     STATUS    RESTARTS   AGE<br>    team01-carbs-7784b95958-pctl5      1/1       Running   0          2m<br><br></code></pre><br><hr><br><hr><br><p>All references to &#60;team&#62; should be replaced with your team name.</p><h4 id="resources-2">Resources</h4><ul><li>K8 yaml    - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/doors.yaml" target="_blank">doors.yaml</a></li><li>Dockerfile - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/doors_Dockerfile" target="_blank">Dockerfile</a></li></ul><h4 id="useful-information-2">Useful information</h4><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Item</th><th align="left">Value</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">cpu:</td><td align="left">50m</td></tr><tr style="background-color: #f8f8f8;"><td align="left">memory:</td><td align="left">50Mi</td></tr><tr style="background-color: #f8f8f8;"><td align="left">image:</td><td align="left">ibmicpcoc/doors:latest</td></tr><tr style="background-color: #f8f8f8;"><td align="left">ports</td><td align="left">none</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Docker</td><td align="left">CMD [&quot;node&quot;, &quot;app.js&quot;]</td></tr></tbody></table><br><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Task description</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">Within your team project diagnose the pod that begins with &#60;team&#62;-doors</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Download the resource K8 yaml file.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Use either of the delete-create-pod or edit-running-pod approaches to resolve the issue.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Did the pod deploy successfully?  If not, correct the issue and re-create the K8 objects.</td></tr></tbody></table><hr><br><p>Check the &quot;tag&quot; of the image that is being pulled. </p><hr><h4 id="diagnosis-2">Diagnosis</h4><p>Describe the pod.</p><br><pre><code><br>-- Get --<br><br>Command:<br><br>    oc get pods <br><br><br>Example output:<br><br>    NAME                         READY     STATUS             RESTARTS   AGE<br>    team01-doors-78b7f6598d-p8kvf   0/1       ImagePullBackOff   0          10m<br><br><br><br>-- Describe --<br><br>Command: <br><br>    oc describe po team01-doors-78b7f6598d-p8kvf<br><br><br>Example output:<br><br>    Name:               team01-doors-78b7f6598d-p8kvf<br>    Namespace:          team01<br>    Priority:           0<br>    PriorityClassName:  &lt;none&gt;<br>    Node:               10.186.56.85/10.186.56.85<br>    Start Time:         Mon, 21 Jan 2019 10:18:18 -0600<br>    Labels:             app=team01-doors<br>                        pod-template-hash=3349118043<br>    . . .<br>            portions of output removed<br>    . . .<br><br>    Events:<br>      Type     Reason     Age                From                   Message<br>      ----     ------     ----               ----                   -------<br>      Normal   Scheduled  46s                default-scheduler      Successfully assigned team01/team01-doors-78b7f6598d-p8kvf to 10.186.56.85<br>      Normal   Pulling    28s (x2 over 43s)  kubelet, 10.186.56.85  pulling image &quot;ibmicpcoc/doors:last&quot;<br>      Warning  Failed     27s (x2 over 43s)  kubelet, 10.186.56.85  Failed to pull image &quot;ibmicpcoc/doors:last&quot;: rpc error: code = Unknown desc = Error response from daemon: manifest for ibmicpcoc/doors:last not found<br>      Warning  Failed     27s (x2 over 43s)  kubelet, 10.186.56.85  Error: ErrImagePull<br>      Normal   BackOff    12s (x3 over 42s)  kubelet, 10.186.56.85  Back-off pulling image &quot;ibmicpcoc/doors:last&quot;<br>      Warning  Failed     12s (x3 over 42s)  kubelet, 10.186.56.85  Error: ImagePullBackOff<br></code></pre><br><p>Multiple Warning messages are displayed in the Events section.  Review all of the Warning messages.</p><br><p>In the &quot;Events&quot; section review the &quot;Message&quot; from the entry with &quot;Type&quot; Warning and &quot;Reason&quot; Failed<br></p><br><pre><code><br>...  Failed to pull image &quot;ibmicpcoc/doors:last&quot;: rpc error: code = Unknown desc = Error response from daemon: manifest for ibmicpcoc/doors:last not found<br><br>(output is from the first Failed message)</code></pre><br><br><br><h4 id="problem-discovered-2">Problem discovered</h4><p>The image cannot be located as indicated by the &quot;Failed to pull image&quot; message.  The image tag last on the container is incorrect.  The image tag should be latest.</p><br><h4 id="resolution-2">Resolution</h4><p>The edit-running-pod is shown in the following example to resolve the issue:</p><br><pre><code><br>-- Edit --<br><br>Command to edit the running pod:<br><br>    OC_EDITOR=&quot;nano&quot; oc -n &lt;team&gt; edit deployment/&lt;team&gt;-doors<br><br><br>Example editor content:  (modify the tag of the image to &quot;latest&quot;)<br><br><br>    # Please edit the object below. Lines beginning with a &#39;#&#39; will be ignored,<br>    # and an empty file will abort the edit. If an error occurs while saving this file will be<br>    # reopened with the relevant failures.<br>    #<br>    apiVersion: extensions/v1beta1<br>    kind: Deployment<br>    metadata:<br>      annotations:<br>        deployment.kubernetes.io/revision: &quot;1&quot;<br>      creationTimestamp: 2019-01-21T16:18:18Z<br>      generation: 1<br>      labels:<br>        app: team01-doors<br>      name: team01-doors<br>      namespace: team01<br>      resourceVersion: &quot;5853628&quot;<br>      selfLink: /apis/extensions/v1beta1/namespaces/team01/deployments/team01-doors<br>      uid: 29914949-1d98-11e9-b012-06ed6a534df5<br>    spec:<br>      progressDeadlineSeconds: 600<br>      replicas: 1<br>      revisionHistoryLimit: 10<br>      selector:<br>        matchLabels:<br>          app: team01-doors<br>      strategy:<br>        rollingUpdate:<br>          maxSurge: 25%<br>          maxUnavailable: 25%<br>        type: RollingUpdate<br>      template:<br>        metadata:<br>          creationTimestamp: null<br>          labels:<br>            app: team01-doors<br>        spec:<br>          containers:<br>          - env:<br>            - name: APP_NAMESPACE<br>              valueFrom:<br>                fieldRef:<br>                  apiVersion: v1<br>                  fieldPath: metadata.namespace<br>            - name: APP_NAME<br>              valueFrom:<br>                fieldRef:<br>                  apiVersion: v1<br>                  fieldPath: metadata.name<br>            - name: COLLECTOR_CONFIG<br>              valueFrom:<br>                configMapKeyRef:<br>                  key: COLLECTOR_CONFIG<br>                  name: team01-collector-config<br>            - name: INSTRUCTOR_CONFIG<br>              valueFrom:<br>                configMapKeyRef:<br>                  key: INSTRUCTOR_CONFIG<br>                  name: team01-collector-config<br>            image: ibmicpcoc/doors:last             &lt;=== change the :last to :latest<br>            imagePullPolicy: Always<br><br>. . . additional content not shown <br><br><br>Ensure you have save the modified file.<br><br><br>Example output:<br><br>    deployment/team01-doors<br></code></pre><br><br><br><p>Validate the pod status is Running.</p><br><pre><code><br>-- Get --<br><br>Command:<br><br>    oc get pods<br><br><br>Example output:<br><br>    NAME                              READY     STATUS    RESTARTS   AGE<br>    team01-doors-767f49c748-6gvcg       1/1       Running   0          1m<br><br></code></pre><br><hr><br><hr><br><p>All references to &#60;team&#62; should be replaced with your team name.</p><h4 id="resources-3">Resources</h4><ul><li>K8 yaml    - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/eagle.yaml" target="_blank">eagle.yaml</a></li><li>Dockerfile - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/eagle_Dockerfile" target="_blank">Dockerfile</a></li></ul><h4 id="useful-information-3">Useful information</h4><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Item</th><th align="left">Value</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">cpu:</td><td align="left">50m</td></tr><tr style="background-color: #f8f8f8;"><td align="left">memory:</td><td align="left">50Mi</td></tr><tr style="background-color: #f8f8f8;"><td align="left">image:</td><td align="left">ibmicpcoc/eagle:latest</td></tr><tr style="background-color: #f8f8f8;"><td align="left">ports</td><td align="left">4100</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Docker</td><td align="left">CMD [&quot;node&quot;, &quot;server.js&quot;]</td></tr></tbody></table><br><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Task description</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">This lab uses the pod with a name that starts with <strong>&#60;team&#62;-eagle</strong></td></tr><tr style="background-color: #f8f8f8;"><td align="left">The web application is not working properly. The application is has a K8 Deployment and Service defined.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Research why the web application is not working properly.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Once you have resolved the issue locate the NodePort (is a number in the 30000 range) for the service.  Example: oc get svc -n &#60;team&#62; -o wide</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Using the same IP that has been used to access the Collector now access the web application using the newly located node port number.  Example URL to access web application:  <strong><a href="http://xxx.xxx.xxx.xxx:NodePort" target="_blank">http://xxx.xxx.xxx.xxx:NodePort</a></strong></td></tr><tr style="background-color: #f8f8f8;"><td align="left">Once the web application is successfully accessed press the button to complete the lab.</td></tr></tbody></table><p><strong>NOTICE:  The last step must be completed to mark the lab complete in the Instructor UI.</strong></p><br><hr><br><ul><li><p>Deployment and Service port definitions must match.  </p></li><li><p>What port should the application be available on?  Refer to <strong>Useful Information</strong>.</p></li></ul><hr><h4 id="diagnosis-3">Diagnosis</h4><p>The pod is running successfully yet describing the pod can provide information about the configured K8 objects.  Describe the pod that begins with: &#60;team&#62;-eagle</p><br><pre><code><br>-- Get pods –-<br><br>Command:<br><br>    oc get po              <br><br><br>Example output:<br><br>    NAME                                 READY     STATUS    RESTARTS   AGE<br>    team10-eagle-56dcf97b6b-msjwt        1/1       Running   0          40s<br><br><br><br>-- Describe pod --<br><br>Command:                  # Use the pod name from the previous output<br><br>    oc describe po team10-eagle-56dcf97b6b-msjwt<br><br><br><br>Example output:<br><br>    Name:               team10-eagle-56dcf97b6b-msjwt<br>    Namespace:          team10<br>    Priority:           0<br>    PriorityClassName:  &lt;none&gt;<br>    Node:               pysyd.159.23.66.104.nip.io/159.23.66.104<br>    Start Time:         Sat, 28 Sep 2019 18:39:25 +1000<br>    Labels:             app=team10-eagle<br>                        pod-template-hash=1287953626<br>    Annotations:        openshift.io/scc=restricted<br>    Status:             Running<br>    IP:                 10.129.0.173<br>    Controlled By:      ReplicaSet/team10-eagle-56dcf97b6b<br>    Containers:<br>      team10-eagle:<br>        Container ID:   docker://05e5e2f6ff0ad45fc5c913953a3442553792848e02bb6401e2bc4f40eb132267<br>        Image:          docker.io/ibmicpcoc/eagle:latest<br>        Image ID:       docker-pullable://docker.io/ibmicpcoc/eagle@sha256:9868019eda5069768539f8b765025caf18d65734d9f6164512332dfbbdf630eb<br>        Port:           4100/TCP<br>        Host Port:      0/TCP<br>        State:          Running<br>          Started:      Sat, 28 Sep 2019 18:39:37 +1000<br>        Ready:          True<br>        Restart Count:  0<br>        Requests:<br>          cpu:     50m<br>          memory:  50Mi<br>        Environment:<br>          APP_NAMESPACE:      team10 (v1:metadata.namespace)<br>          APP_NAME:           team10-eagle-56dcf97b6b-msjwt (v1:metadata.name)<br>          COLLECTOR_CONFIG:   &lt;set to the key &#39;COLLECTOR_CONFIG&#39; of config map &#39;team10-collector-config&#39;&gt;   Optional: false<br>          INSTRUCTOR_CONFIG:  &lt;set to the key &#39;INSTRUCTOR_CONFIG&#39; of config map &#39;team10-collector-config&#39;&gt;  Optional: false<br>        Mounts:<br>          /var/run/secrets/kubernetes.io/serviceaccount from default-token-kcr98 (ro)<br>    Conditions:<br>      Type              Status<br>      Initialized       True<br>      Ready             True<br>      ContainersReady   True<br>      PodScheduled      True<br>    Volumes:<br>      default-token-kcr98:<br>        Type:        Secret (a volume populated by a Secret)<br>        SecretName:  default-token-kcr98<br>        Optional:    false<br>    QoS Class:       Burstable<br>    Node-Selectors:  node-role.kubernetes.io/compute=true<br>    Tolerations:     node.kubernetes.io/memory-pressure:NoSchedule<br>    Events:<br>      Type    Reason     Age   From                                 Message<br>      ----    ------     ----  ----                                 -------<br>      Normal  Scheduled  48s   default-scheduler                    Successfully assigned team10/team10-eagle-56dcf97b6b-msjwt to pysyd.159.23.66.104.nip.io<br>      Normal  Pulling    44s   kubelet, pysyd.159.23.66.104.nip.io  pulling image &quot;docker.io/ibmicpcoc/eagle:latest&quot;<br>      Normal  Pulled     35s   kubelet, pysyd.159.23.66.104.nip.io  Successfully pulled image &quot;docker.io/ibmicpcoc/eagle:latest&quot;<br>      Normal  Created    35s   kubelet, pysyd.159.23.66.104.nip.io  Created container<br>      Normal  Started    35s   kubelet, pysyd.159.23.66.104.nip.io  Started container</code></pre><br><p>Review the port definitions from the describe output.</p><br><p>Describe the service defined for this pod.</p><br><pre><code><br>-- Get Services --<br><br>Command:<br><br>    oc get svc<br><br><br><br>Example output:<br><br><br>    NAME                TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE<br>    team10-eagle        NodePort   172.30.100.2     &lt;none&gt;        80:31024/TCP   1h<br>    team10-igloo        NodePort   172.30.224.252   &lt;none&gt;        80:30814/TCP   2h<br>    team10-jazzy        NodePort   172.30.217.79    &lt;none&gt;        80:30092/TCP   1h<br>    team10-quake        NodePort   172.30.69.77     &lt;none&gt;        80:30836/TCP   3h<br>    team10-salty        NodePort   172.30.174.1     &lt;none&gt;        80:30624/TCP   2h<br>    team10-student-ui   NodePort   172.30.89.80     &lt;none&gt;        80:31010/TCP   1d<br><br><br>-- Describe service --<br><br>Command:<br><br>    oc describe svc team10-eagle<br><br><br>Example outpot:<br><br><br>    Name:                     team10-eagle<br>    Namespace:                team10<br>    Labels:                   app=team10-eagle<br>    Annotations:              &lt;none&gt;<br>    Selector:                 app=team10-eagle<br>    Type:                     NodePort<br>    IP:                       172.30.225.217<br>    Port:                     team10-eagle  80/TCP<br>    TargetPort:               4010/TCP<br>    NodePort:                 team10-eagle  32308/TCP<br>    Endpoints:                10.129.0.173:4010<br>    Session Affinity:         None<br>    External Traffic Policy:  Cluster<br>    Events:                   &lt;none&gt;<br><br></code></pre><br><h4 id="problem-discovered-3">Problem discovered</h4><br><p>The ports do not match for the Deployment and Service definitions.  The values are 4100 and 4010.</p><h4 id="resolution-3">Resolution</h4><p>Edit the Service definition and change the port from 4010 to 4100.</p><p><strong>NOTE: Complete this lab by accessing the URL and pressing the button shown in the browser with the value &#39;Click to complete lab!&#39;.</strong></p><p>Example URL using the master IP and the node port from the service definition after fixing the above issue.</p><br><pre><code>    http://159.23.66.107:31024/</code></pre><hr><hr><br><p>All references to &#60;team&#62; should be replaced with your team name.</p><h4 id="resources-4">Resources</h4><ul><li>K8 yaml    - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/floor.yaml" target="_blank">floor.yaml</a></li><li>Dockerfile - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/floor_Dockerfile" target="_blank">Dockerfile</a></li></ul><h4 id="useful-information-4">Useful information</h4><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Item</th><th align="left">Value</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">cpu:</td><td align="left">50m</td></tr><tr style="background-color: #f8f8f8;"><td align="left">memory:</td><td align="left">50Mi</td></tr><tr style="background-color: #f8f8f8;"><td align="left">image:</td><td align="left">ibmicpcoc/floor:latest</td></tr><tr style="background-color: #f8f8f8;"><td align="left">ports</td><td align="left">none</td></tr><tr style="background-color: #f8f8f8;"><td align="left">YAML</td><td align="left">command: [&quot;node&quot;, &quot;app.js&quot;]</td></tr></tbody></table><br><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Task description</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">A container within a successfully deployed pod is not working properly.  Research the running container to diagnose the issue.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">View the logs of the running container.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Correct the issue inside the running container.</td></tr></tbody></table><hr><br><ul><li>Exec into the running container</li><li>Use touch, nano, or echo with piping to assist in resolving the issue</li></ul><hr><h4 id="diagnosis-4">Diagnosis</h4><p>Check the logs of the running container that begins with &#60;team&#62;</p><br><pre><code><br>-- Get --<br><br>Command :<br><br>    oc get pods                 <br><br><br><br>Example output:<br><br>    NAME                              READY     STATUS    RESTARTS   AGE<br>    team01-floor-6ff9f54f44-zpchp       1/1       Running   0          41s<br><br><br><br>-- Logs --<br><br>Command:<br>    oc logs -f team01-floor-6ff9f54f44-zpchp            <br><br><br>Example output:<br><br>    Note the instructions from viewing the log<br><br>    1/21/2019, 10:21:14 PM :: clnt012i - Check for file: /app/team.txt check count: 43<br>    1/21/2019, 10:21:14 PM :: clnt013i - The file team.txt in the /app directory must exist for this lab to be completed.<br>    1/21/2019, 10:21:14 PM :: clnt014i - Create the file in the running container.<br><br></code></pre><br><h4 id="problem-discovered-4">Problem discovered</h4><br><p>The file team.txt is missing from the /app directory in the running container.</p><h4 id="resolution-4">Resolution</h4><p>Here are two methods that can be used to resolve the creating of the file.  </p><blockquote><p>First method is to run a &quot;command&quot; using the oc CLI from outside the container.</p></blockquote><br><br><pre><code><br>-- Get --<br><br>Command to get pods in namespace<br><br>    oc get po<br><br><br>Example output:<br><br>    NAME                              READY     STATUS    RESTARTS   AGE<br>    team01-floor-6ff9f54f44-zpchp       1/1       Running   0          41s<br></code></pre><br><p>Add the team.txt file using the touch command from outside the container.</p><br><br><pre><code><br>-- Exec --<br><br>Command:<br><br>    oc exec -n team01 team01-floor-6ff9f54f44-zpchp -- sh -c &quot;touch /app/team.txt&quot;<br><br>    The above command is using &#39;sh&#39;.  <br><br><br><br>Example output:  (wait a few seconds for the messages to show)<br><br>    1/21/2019, 10:25:30 PM :: clnt014i - Create the file in the running container.<br>    1/21/2019, 10:25:45 PM :: ----------------------------------------------------------------------------------<br>    1/21/2019, 10:25:45 PM :: clnt008i - File located.  Reporting to collector.<br>    1/21/2019, 10:25:45 PM :: ----------------------------------------------------------------------------------<br>    1/21/2019, 10:25:45 PM :: clnt007i - Student count: 61 from /team01/team01-floor-6ff9f54f44-zpchp<br>    1/21/2019, 10:25:45 PM :: clnt010i - Instructor count: 1 from /team01/team01-floor-6ff9f54f44-<br><br>    The clnt007i and clnt010i messages are produced once the file has been located.<br><br></code></pre><br><br><br><blockquote><p>Second method is to exec into the running container and create the file from a shell prompt.  This method requires &#39;sh&#39; capability must be installed in the container for this to work.</p></blockquote><br><br><pre><code><br>-- Get --<br><br>Command to get pods in namespace<br><br>    oc get po<br><br><br><br>Example output from &quot;team01&quot; namespace    <br><br>    NAME                              READY     STATUS    RESTARTS   AGE<br>    team01-floor-6ff9f54f44-zpchp       1/1       Running   0          41s<br><br><br><br><br>-- Exec to open a terminal session with the running container --<br><br>Command:<br><br>    oc exec -it team01-floor-6ff9f54f44-zpchp -- sh<br><br>    Note: The above command is using &#39;sh&#39;.  The &#39;sh&#39; capability must be installed in the container for this to work.<br><br><br><br>Example result output:<br><br>    /app #<br><br><br><br>-- Create the file using touch --<br><br>Command:<br><br>    touch team.txt                   <br><br>    Notice the &quot;/app&quot; directory is not included as part of the touch command since the prompt is open to that directory.<br><br><br><br>Example output:  (wait a few seconds for the messages to show)<br><br>    1/21/2019, 10:25:30 PM :: clnt014i - Create the file in the running container.<br>    1/21/2019, 10:25:45 PM :: ----------------------------------------------------------------------------------<br>    1/21/2019, 10:25:45 PM :: clnt008i - File located.  Reporting to collector.<br>    1/21/2019, 10:25:45 PM :: ----------------------------------------------------------------------------------<br>    1/21/2019, 10:25:45 PM :: clnt007i - Student count: 61 from /team01/team01-floor-6ff9f54f44-zpchp<br>    1/21/2019, 10:25:45 PM :: clnt010i - Instructor count: 1 from /team01/team01-floor-6ff9f54f44-<br><br>    The clnt007i and clnt010i messages are produced once the file has been located.<br><br></code></pre><br><hr><br><hr><br><p>All references to &#60;team&#62; should be replaced with your team name.</p><h4 id="resources-5">Resources</h4><ul><li>K8 yaml    - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/gonzo.yaml" target="_blank">gonzo.yaml</a></li><li>Dockerfile - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/gonzo_Dockerfile" target="_blank">Dockerfile</a></li></ul><h4 id="useful-information-5">Useful information</h4><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Item</th><th align="left">Value</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">cpu:</td><td align="left">50m</td></tr><tr style="background-color: #f8f8f8;"><td align="left">memory:</td><td align="left">50Mi</td></tr><tr style="background-color: #f8f8f8;"><td align="left">image:</td><td align="left">ibmicpcoc/gonzo:latest</td></tr><tr style="background-color: #f8f8f8;"><td align="left">ports</td><td align="left">none</td></tr><tr style="background-color: #f8f8f8;"><td align="left">YAML</td><td align="left">command: [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;/app/app.sh gonzo&quot;]</td></tr></tbody></table><hr><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Task description</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">A pod that begins with &#60;team&#62;-gonzo is failing creation.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Research the issue to determine what is causing the failure.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Edit the gonzo.yaml file to correct the issue.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Verify the deployment successfully deployed</td></tr></tbody></table><hr><br><ul><li>What ENTRYPOINT or CMD is defined for the Docker image?</li><li>What container &quot;command&quot; parameter is defined for the pod definition?</li><li>Command: docker history ibmicpcoc/gonzo --no-trunc can also be used to check the docker image.</li><li>The gonzo.yaml must be modified to correct the issue.  You will not be allowed to rebuild or modify the Docker image.</li></ul><hr><h4 id="diagnosis-5">Diagnosis</h4><br><pre><code><br>-- Get --<br><br>Command:<br><br>    oc get po<br><br><br><br>Example output:<br><br>    NAME                              READY     STATUS             RESTARTS   AGE<br>    team01-gonzo-75d79787b7-88pnr       0/1       CrashLoopBackOff   4          2m<br><br><br><br>-- Describe --<br><br>Command:<br><br>    oc describe pod team01-gonzo-75d79787b7-88pnr <br><br><br><br>Example output:<br><br>    Name:               team01-gonzo-75d79787b7-88pnr<br>    Namespace:          team01<br>    Priority:           0<br>    PriorityClassName:  &lt;none&gt;<br>    Node:               10.186.56.85/10.186.56.85<br>    Start Time:         Mon, 21 Jan 2019 18:13:15 -0600<br>    Labels:             app=team01-gonzo<br>                        pod-template-hash=3183534363<br>    . . .<br>            portions of output removed<br>    . . .<br><br>    Conditions:<br>      Type              Status<br>      Initialized       True<br>      Ready             False<br>      ContainersReady   False<br>      PodScheduled      True<br>    Volumes:<br>      default-token-mq64m:<br>        Type:        Secret (a volume populated by a Secret)<br>        SecretName:  default-token-mq64m<br>        Optional:    false<br>    QoS Class:       Burstable<br>    Node-Selectors:  &lt;none&gt;<br>    Tolerations:     node.kubernetes.io/memory-pressure:NoSchedule<br>                     node.kubernetes.io/not-ready:NoExecute for 300s<br>                     node.kubernetes.io/unreachable:NoExecute for 300s<br>    Events:<br>      Type     Reason     Age                 From                   Message<br>      ----     ------     ----                ----                   -------<br>      Normal   Scheduled  11m                 default-scheduler      Successfully assigned team01/team01-gonzo-75d79787b7-88pnr to 10.186.56.85<br>      Normal   Created    10m (x4 over 11m)   kubelet, 10.186.56.85  Created container<br>      Normal   Started    10m (x4 over 11m)   kubelet, 10.186.56.85  Started container<br>      Normal   Pulling    9m (x5 over 11m)    kubelet, 10.186.56.85  pulling image &quot;ibmicpcoc/gonzo:latest&quot;<br>      Normal   Pulled     9m (x5 over 11m)    kubelet, 10.186.56.85  Successfully pulled image &quot;ibmicpcoc/gonzo:latest&quot;<br>      Warning  BackOff    58s (x46 over 11m)  kubelet, 10.186.56.85  Back-off restarting failed container                <br></code></pre><br><p>In the &quot;Events&quot; section review the &quot;Message&quot; from the entry with &quot;Type&quot; Warning and &quot;Reason&quot; BackOff<br><br></p><br><pre><code>... Back-off restarting failed container</code></pre><p>Check the image for the command or entrypoint defined to execute when the container is created</p><ul><li><p>Review the Dockerfile provided in the Resources section of this lab.</p></li><li><p>Browse the Dockerfile and review the entrypoint or command defined to start when container is created.</p></li></ul><p>(or)    </p><ul><li>Check the Docker image using the following command:</li></ul><br><pre><code>    docker history ibmicpcoc/gonzo --no-trunc     </code></pre><h4 id="problem-discovered-5">Problem discovered</h4><p>The container is ending as soon as it starts.  The entrypoint or command that executes when the container starts is not defined in either the Dockerfile or gonzo.yaml file.  </p><h4 id="resolution-5">Resolution</h4><p>Add the &quot;command&quot; parameter to the pod container definition using the file gonzo.yaml provided in the Resources section of this lab.  The &quot;command&quot; parameter should define the bash script /app/gonzo.sh using /bin/bash</p><br><pre><code>Example parameter:<br><br>    command: [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;/app/gonzo.sh&quot;]</code></pre><br><p>Add the &quot;command&quot; parameter to the container.  </p><br><br><pre><code><br>-- Example of of the modified yaml file --<br><br>apiVersion: apps/v1<br>kind: Deployment<br>metadata:<br>  name: team01-gonzo<br>  namespace: team01<br>  labels:<br>    app: team01-gonzo<br>spec:<br>  selector:<br>    matchLabels:<br>      app: team01-gonzo<br>  replicas: 1<br>  template:<br>    metadata:<br>      labels:<br>        app: team01-gonzo<br>    spec:<br>      containers:<br>      - name: team01-gonzo<br>        image: ibmicpcoc/gonzo:latest<br>        imagePullPolicy: Always<br>        command: [&quot;/bin/bash&quot;, &quot;-c&quot;, &quot;/app/gonzo.sh&quot;]    &lt;=== inserted this line<br><br>. . .  reaminder of file not shown . . .<br></code></pre><br><p>Re-deploy the pod and verify the pod is running.  There will be no visible log messages so the <strong>oc describe</strong> command must be used for validation.</p><br><hr><hr><br><p>All references to &#60;team&#62; should be replaced with your team name.</p><h4 id="resources-6">Resources</h4><ul><li>K8 yaml    - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/igloo.yaml" target="_blank">igloo.yaml</a></li><li>Dockerfile - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/igloo_Dockerfile" target="_blank">Dockerfile</a></li></ul><h4 id="useful-information-6">Useful information</h4><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Item</th><th align="left">Value</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">Misc</td><td align="left">Readiness and Liveness probes defined</td></tr></tbody></table><br><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Task description</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">A pod that begins with &#60;team&#62;-igloo is frequently restarting.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Research the issue to determine what is causing the pod to restart frequently.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Review the pod log to determine how long the http server waits to be started.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Edit the igloo.yaml file to correct the issue.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Verify the deployment successfully deployed.</td></tr></tbody></table><br><p><strong>The target url must be accessed to mark this task complete.</strong></p><p>Once issue is successfully resolved perform the following.</p><ul><li>Get the NodePort for the &#60;team&#62;-igloo service.</li><li>Get the IP address for the master node.</li><li>Using the above NodePort and the master IP address access the url: http://<master ip>:<NodePort> to mark the task as complete.</li></ul><hr><br><ul><li>How long do both probes delay before starting?</li></ul><hr><h4 id="diagnosis-6">Diagnosis</h4><br><pre><code><br>-- Get pods --<br><br>Command: <br><br>    oc -n &lt;team&gt; get pods                 &lt;=== Replace &lt;team&gt;<br><br>    (if in team project already)<br><br>    oc get po<br><br><br><br>Example output:<br><br>   NAME                         READY     STATUS    RESTARTS   AGE<br>   team20-igloo-7b85976d87-x6z6r   0/1       Running   3          2m<br><br><br><br>-- Describe --<br><br>Command:<br><br>    oc describe po team20-igloo-7b85976d87-x6z6r<br><br><br><br>Example output:    <br><br>    Name:               team20-igloo-7b85976d87-x6z6r<br>    Namespace:          team20<br>    Priority:           0<br>    PriorityClassName:  &lt;none&gt;<br>    Node:               gfstst.169.62.225.201.nip.io/169.62.225.201<br>    Start Time:         Tue, 03 Sep 2019 20:06:13 -0400<br>    Labels:             app=team20-igloo<br>                        pod-template-hash=3641532843<br>    Annotations:        openshift.io/scc=restricted<br>    Status:             Running<br>    IP:                 10.129.0.94<br>    Controlled By:      ReplicaSet/team20-igloo-7b85976d87<br>    Containers:<br>      team20-igloo:<br>        Container ID:   docker://e9b6049395fa281c1ca0d6e63001ac3226fc211c5948bf1673023c9dc6f74f37<br>        Image:          ibmicpcoc/igloo:latest<br>        Image ID:       docker-pullable://docker.io/ibmicpcoc/igloo@sha256:4968f5c1ca641e3267d9a163c68eceb307973e06a30df51a47d86dcd0e301a40<br>        Port:           &lt;none&gt;<br>        Host Port:      &lt;none&gt;<br>        State:          Running<br>          Started:      Tue, 03 Sep 2019 20:06:49 -0400<br>        Last State:     Terminated<br>          Reason:       Error<br>          Exit Code:    137<br>          Started:      Tue, 03 Sep 2019 20:06:16 -0400<br>          Finished:     Tue, 03 Sep 2019 20:06:48 -0400<br>        Ready:          False<br>        Restart Count:  1<br>        Requests:<br>          cpu:      50m<br>          memory:   50Mi<br>        Liveness:   http-get http://:4100/health delay=1s timeout=1s period=2s #success=1 #failure=1<br>        Readiness:  http-get http://:4100/ready delay=1s timeout=1s period=5s #success=1 #failure=3<br>        Environment:<br>          APP_NAMESPACE:      team20 (v1:metadata.namespace)<br>          APP_NAME:           team20-igloo-7b85976d87-x6z6r (v1:metadata.name)<br>          COLLECTOR_CONFIG:   &lt;set to the key &#39;COLLECTOR_CONFIG&#39; of config map &#39;team20-collector-config&#39;&gt;   Optional: false<br>          INSTRUCTOR_CONFIG:  &lt;set to the key &#39;INSTRUCTOR_CONFIG&#39; of config map &#39;team20-collector-config&#39;&gt;  Optional: false<br>        Mounts:<br>          /var/run/secrets/kubernetes.io/serviceaccount from default-token-dxnzt (ro)<br>    Conditions:<br>      Type              Status<br>      Initialized       True<br>      Ready             False<br>      ContainersReady   False<br>      PodScheduled      True<br>    Volumes:<br>      default-token-dxnzt:<br>        Type:        Secret (a volume populated by a Secret)<br>        SecretName:  default-token-dxnzt<br>        Optional:    false<br>    QoS Class:       Burstable<br>    Node-Selectors:  node-role.kubernetes.io/compute=true<br>    Tolerations:     node.kubernetes.io/memory-pressure:NoSchedule<br>    Events:<br>      Type     Reason     Age               From                                   Message<br>      ----     ------     ----              ----                                   -------<br>      Normal   Scheduled  42s               default-scheduler                      Successfully assigned team20/team20-igloo-7b85976d87-x6z6r to gfstst.169.62.225.201.nip.io<br>      Normal   Pulling    7s (x2 over 40s)  kubelet, gfstst.169.62.225.201.nip.io  pulling image &quot;ibmicpcoc/igloo:latest&quot;<br>      Normal   Killing    7s                kubelet, gfstst.169.62.225.201.nip.io  Killing container with id docker://team20-igloo:Container failed liveness probe.. Container will be killed and recreated.<br>      Normal   Pulled     6s (x2 over 39s)  kubelet, gfstst.169.62.225.201.nip.io  Successfully pulled image &quot;ibmicpcoc/igloo:latest&quot;<br>      Normal   Created    6s (x2 over 39s)  kubelet, gfstst.169.62.225.201.nip.io  Created container<br>      Normal   Started    6s (x2 over 39s)  kubelet, gfstst.169.62.225.201.nip.io  Started container<br>      Warning  Unhealthy  4s (x2 over 38s)  kubelet, gfstst.169.62.225.201.nip.io  Liveness probe failed: Get http://10.129.0.94:4100/health: dial tcp 10.129.0.94:4100: connect: connection refused<br>      Warning  Unhealthy  2s (x3 over 37s)  kubelet, gfstst.169.62.225.201.nip.io  Readiness probe failed: Get http://10.129.0.94:4100/ready: dial tcp 10.129.0.94:4100: connect: connection refused<br><br></code></pre><br><h4 id="problem-discovered-6">Problem discovered</h4><br><p>The liveness and readiness probes do not wait long enough for the pod to successfully start.  These probes must ensure there are configured to wait long enough for the pod to start before checking.</p><h4 id="resolution-6">Resolution</h4><p>Modify the readinessProbe initialDelaySeconds to 15 seconds and the livenessProbe initialDelaySeconds to 20 seconds.  This will allow the pod to start before the probes begin checking.</p><p>Example modifications to the parameters:</p><br><pre><code><br>        readinessProbe:<br>          httpGet:<br>            path: /ready<br>            port: 4100<br>          initialDelaySeconds: 15       &lt;&lt;&lt;--- modified<br>          timeoutSeconds: 1<br>          periodSeconds: 5<br>          successThreshold: 1<br>          failureThreshold: 3<br><br>        livenessProbe:<br>          httpGet:<br>            path: /health<br>            port: 4100<br>          initialDelaySeconds: 20       &lt;&lt;&lt;--- modified<br>          timeoutSeconds: 1<br>          periodSeconds: 15 <br>          failureThreshold: 1</code></pre><br><hr><br><hr><br><p>All references to &#60;team&#62; should be replaced with your team name.</p><h4 id="resources-7">Resources</h4><ul><li>K8 yaml    - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/jazzy.yaml" target="_blank">jazzy.yaml</a></li><li>Dockerfile - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/jazzy_Dockerfile" target="_blank">Dockerfile</a></li></ul><h4 id="useful-information-7">Useful information</h4><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Item</th><th align="left">Value</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">cpu:</td><td align="left">50m</td></tr><tr style="background-color: #f8f8f8;"><td align="left">memory:</td><td align="left">50Mi</td></tr><tr style="background-color: #f8f8f8;"><td align="left">image:</td><td align="left">ibmicpcoc/jazzy:latest</td></tr><tr style="background-color: #f8f8f8;"><td align="left">ports</td><td align="left">9000</td></tr><tr style="background-color: #f8f8f8;"><td align="left">YAML</td><td align="left">command: [&quot;node&quot;, &quot;app.js&quot;]</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Misc</td><td align="left">Application waits</td></tr></tbody></table><br><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Task description</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">A pod that begins with &#60;team&#62;-jazzy has started successfully.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Review the pod logs.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Can the pod access the target URL as defined in the <strong>YARNS_URL</strong> environment variable.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Remote into the pod and use <strong>curl</strong> to test accessing the yarns service that is running in the <strong>default</strong> namespace.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Edit the jazzy.yaml file to correct the issue by modifying the <strong>YARNS_URL</strong> environment variable.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Verify the pod is successfully communicating with the yarns service.  Success is indicated by the presence of the <strong>jazz400i</strong> in the log messages.</td></tr></tbody></table><hr><br><ul><li><p>You need to tell the service which namespace to communicate with if it is not in the same namespace.</p></li><li><p>Review the environment variable &quot;INSTRUCTOR_CONFIG&quot; as this points to a service in the <strong>default</strong> namespace.</p></li></ul><hr><h4 id="diagnosis-7">Diagnosis</h4><br><pre><code><br>Notice: use the oc get pods to obtain the pod name<br><br>-- Logs --<br><br>Command:<br><br>    oc logs team20-jazzy-5ffc4f7-4n8qg<br><br><br><br>Example output:<br><br>    9/28/2019, 3:25:13 AM :: jazz003i - Environment APP_NAMESPACE: team20<br>    9/28/2019, 3:25:13 AM :: jazz004i - Environment APP_NAME: Using random key = team20-jazzy-5ffc4f7-4n8qg<br>    9/28/2019, 3:25:13 AM :: jazz005i - Environment COLLECTOR_CONFIG: http://team20-student-ui<br>    9/28/2019, 3:25:13 AM :: jazz006i - Environment INSTRUCTOR_CONFIG: http://dashboard.default<br>    9/28/2019, 3:25:13 AM :: jazz007i - Environment YARNS_URL: http://yarns<br>    9/28/2019, 3:25:13 AM :: jazz017i - Jazzy Server is asking yarns data server for data<br>    9/28/2019, 3:25:13 AM :: jazz500i - Invoke startAsking<br>    9/28/2019, 3:25:13 AM :: jazz014i - Start asking data server for information<br>    9/28/2019, 3:25:13 AM :: jazz032e - Error asking yarns data server, count: 1<br>    {<br>        &quot;errno&quot;: &quot;ENOTFOUND&quot;,<br>        &quot;code&quot;: &quot;ENOTFOUND&quot;,<br>        &quot;syscall&quot;: &quot;getaddrinfo&quot;,<br>        &quot;hostname&quot;: &quot;yarns&quot;,<br>        &quot;host&quot;: &quot;yarns&quot;,<br>        &quot;port&quot;: 80<br>    } <br><br><br><br>-- RSH --<br><br>Command:<br><br>     oc rsh team20-jazzy-5ffc4f7-4n8qg<br><br><br><br>Example output:<br><br>    /app $<br><br><br><br>-- curl test 1 --<br><br>Commands:<br><br>    curl http://yarns<br><br><br><br>Example output:<br><br>    curl: (6) Could not resolve host: yarns<br><br><br><br>-- curl test 2 --<br><br>Commands:<br><br>    curl http://yarns.default<br><br><br><br>Example output:<br><br>    Yarns server is ready     <br><br></code></pre><br><h4 id="problem-discovered-7">Problem discovered</h4><br><p>The pod is unable to communicate with the target URL as configured.  Error message <strong>jazz032e</strong> indicates the pod cannot access the yarns service.</p><h4 id="resolution-7">Resolution</h4><p>Modify the target YARNS_URL in the environment variables to the appropriate URL.<br>Verify the pod is communicating with yarns service.</p><br><pre><code><br>Notice: use the oc get pods to obtain the pod name<br><br>-- Logs --<br><br>Command:<br><br>    oc logs team20-jazzy-76f6879566-nxlbc<br><br><br><br>Example output:<br><br>    9/28/2019, 3:44:20 AM :: jazz003i - Environment APP_NAMESPACE: team20<br>    9/28/2019, 3:44:20 AM :: jazz004i - Environment APP_NAME: Using random key = team20-jazzy-76f6879566-nxlbc<br>    9/28/2019, 3:44:20 AM :: jazz005i - Environment COLLECTOR_CONFIG: http://team20-student-ui<br>    9/28/2019, 3:44:20 AM :: jazz006i - Environment INSTRUCTOR_CONFIG: http://dashboard.default<br>    9/28/2019, 3:44:20 AM :: jazz007i - Environment YARNS_URL: http://yarns.default<br>    9/28/2019, 3:44:20 AM :: jazz017i - Jazzy Server is asking yarns data server for data<br>    9/28/2019, 3:44:20 AM :: jazz500i - Invoke startAsking<br>    9/28/2019, 3:44:20 AM :: jazz014i - Start asking data server for information<br>    9/28/2019, 3:44:20 AM :: jazz400i - Success<br><br><br>NOTICE the jazz400i message indicating success.<br><br></code></pre><br><hr><br><hr><br><p>All references to &#60;team&#62; should be replaced with your team name.</p><h4 id="resources-8">Resources</h4><ul><li>K8 yaml    - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/karma.yaml" target="_blank">karma.yaml</a></li><li>Dockerfile - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/karma_Dockerfile" target="_blank">Dockerfile</a></li></ul><h4 id="useful-information-8">Useful information</h4><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Item</th><th align="left">Value</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">cpu:</td><td align="left">50m</td></tr><tr style="background-color: #f8f8f8;"><td align="left">memory:</td><td align="left">50Mi</td></tr><tr style="background-color: #f8f8f8;"><td align="left">image:</td><td align="left">ibmicpcoc/karma:latest</td></tr><tr style="background-color: #f8f8f8;"><td align="left">YAML</td><td align="left">command: [&quot;node&quot;, &quot;app.js&quot;]</td></tr></tbody></table><br><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Task description</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">A pod that begins with &#60;team&#62;-karma is in a CrashLoopBackOff state.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Research the issue to determine what is causing the pod to restart frequently.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Review the pod log to determine how long the application http server waits to be started.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Editing the karma.yaml <strong>WILL NOT</strong> correct the issue.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Resolution will require using <strong>oc adm policy</strong> command</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Ensure the pod is deleted and restarts after fixing the issue.</td></tr></tbody></table><hr><br><ul><li>Are pods permitted to run as root?</li></ul><hr><h4 id="diagnosis-8">Diagnosis</h4><br><pre><code><br>NOTE: Get the pod name using the oc get pods <br><br>-- Describe --<br><br>Command:<br><br>    oc describe po team14-karma-7db6fb5cc9-6kjcg<br><br><br><br>Example output:<br><br>    Name:               team14-karma-7db6fb5cc9-6kjcg<br>    Namespace:          team14<br>    Priority:           0<br>    PriorityClassName:  &lt;none&gt;<br>    Node:               pysyd.159.23.66.101.nip.io/159.23.66.101<br>    Start Time:         Sat, 28 Sep 2019 12:35:07 +1000<br>    Labels:             app=team14-karma<br>                        pod-template-hash=3862961775<br>    Annotations:        openshift.io/scc=restricted<br>    Status:             Running<br>    IP:                 10.130.1.186<br>    Controlled By:      ReplicaSet/team14-karma-7db6fb5cc9<br>    Containers:<br>      team14-karma:<br>        Container ID:  docker://215630c1bcc8861b1679062155bc87240f1cbbabc848277a06c1fc5f5c83b675<br>        Image:         docker.io/ibmicpcoc/karma:latest<br>        Image ID:      docker-pullable://docker.io/ibmicpcoc/karma@sha256:e84351a5833886d42a113b317d9527afe3aa5d8bbc7da5112be0ab9b5058e59c<br>        Port:          &lt;none&gt;<br>        Host Port:     &lt;none&gt;<br>        Command:<br>          node<br>          app.js<br>        State:          Waiting<br>          Reason:       CrashLoopBackOff<br>        Last State:     Terminated<br>          Reason:       Error<br>          Exit Code:    1<br>          Started:      Sat, 28 Sep 2019 12:46:22 +1000<br>          Finished:     Sat, 28 Sep 2019 12:46:22 +1000<br>        Ready:          False<br>        Restart Count:  7<br>        Requests:<br>          cpu:     50m<br>          memory:  50Mi<br>        Environment:<br>          APP_NAMESPACE:      team14 (v1:metadata.namespace)<br>          APP_NAME:           team14-karma-7db6fb5cc9-6kjcg (v1:metadata.name)<br>          COLLECTOR_CONFIG:   &lt;set to the key &#39;COLLECTOR_CONFIG&#39; of config map &#39;team14-collector-config&#39;&gt;   Optional: false<br>          INSTRUCTOR_CONFIG:  &lt;set to the key &#39;INSTRUCTOR_CONFIG&#39; of config map &#39;team14-collector-config&#39;&gt;  Optional: false<br>        Mounts:<br>          /var/run/secrets/kubernetes.io/serviceaccount from default-token-lzmmh (ro)<br>    Conditions:<br>      Type              Status<br>      Initialized       True<br>      Ready             False<br>      ContainersReady   False<br>      PodScheduled      True<br>    Volumes:<br>      default-token-lzmmh:<br>        Type:        Secret (a volume populated by a Secret)<br>        SecretName:  default-token-lzmmh<br>        Optional:    false<br>    QoS Class:       Burstable<br>    Node-Selectors:  node-role.kubernetes.io/compute=true<br>    Tolerations:     node.kubernetes.io/memory-pressure:NoSchedule<br>    Events:<br>      Type     Reason     Age                 From                                 Message<br>      ----     ------     ----                ----                                 -------<br>      Normal   Scheduled  16m                 default-scheduler                    Successfully assigned team14/team14-karma-7db6fb5cc9-6kjcg to pysyd.159.23.66.101.nip.io<br>      Normal   Created    15m (x4 over 15m)   kubelet, pysyd.159.23.66.101.nip.io  Created container<br>      Normal   Started    15m (x4 over 15m)   kubelet, pysyd.159.23.66.101.nip.io  Started container<br>      Normal   Pulling    14m (x5 over 15m)   kubelet, pysyd.159.23.66.101.nip.io  pulling image &quot;docker.io/ibmicpcoc/karma:latest&quot;<br>      Normal   Pulled     14m (x5 over 15m)   kubelet, pysyd.159.23.66.101.nip.io  Successfully pulled image &quot;docker.io/ibmicpcoc/karma:latest&quot;<br>      Warning  BackOff    49s (x66 over 15m)  kubelet, pysyd.159.23.66.101.nip.io  Back-off restarting failed container<br><br><br><br>-- Logs --<br><br>Command: <br><br>    oc logs team14-karma-7db6fb5cc9-6kjcg<br><br><br><br>Example output:<br><br>    9/28/2019, 2:46:22 AM :: karm001i - Application random key: b42bde37-f4f2-40f1-9ae9-6b7b80b2442c<br>    9/28/2019, 2:46:22 AM :: karm003i - Environment APP_NAMESPACE: team14<br>    9/28/2019, 2:46:22 AM :: karm004i - Environment APP_NAME: Using random key = team14-karma-7db6fb5cc9-6kjcg<br>    9/28/2019, 2:46:22 AM :: karm013i - Environment COLLECTOR_CONFIG: http://team14-student-ui<br>    9/28/2019, 2:46:22 AM :: karm014i - Environment INSTRUCTOR_CONFIG: http://dashboard.default<br>    9/28/2019, 2:46:22 AM :: karm109e - Error writing file: /app/karma.txt  Error message: Error: EACCES: permission denied, open &#39;/app/karma.txt&#39;<br><br></code></pre><br><h4 id="problem-discovered-8">Problem discovered</h4><br><p>Error message: <strong>Error: EACCES: permission denied, open &#39;/app/karma.txt&#39;</strong> is indicating the pod lacks permissions.  By default, OpenShift does not allow running privileged pods.  By default, Docker builds images with &quot;root&quot; user making the it privileged.  </p><h4 id="resolution-8">Resolution</h4><p>Add the security policy anyuid to the service account responsible for creating your deployment, by default this user is default. The dash z indicates that we want to manipulate a service account.</p><p>User either of the following commands:</p><ul><li><p>oc adm policy add-scc-to-user anyuid -z default</p></li><li><p>oc adm policy add-scc-to-user anyuid system:serviceaccount:&#60;team&#62;:default </p></li></ul><p>NOTE: If second command above is used, replace <strong>&#60;team&#62;</strong> with team name.</p><p>After issuing the command the pod will need to be deleted.  Once deleted the pod will restart and will then be able to run as a privileged pod.</p><hr><hr><br><p>All references to &#60;team&#62; should be replaced with your team name.</p><h4 id="resources-9">Resources</h4><ul><li>K8 yaml    - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/lacey.yaml" target="_blank">lacey.yaml</a></li><li>Dockerfile - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/lacey_Dockerfile" target="_blank">Dockerfile</a></li></ul><h4 id="useful-information-9">Useful information</h4><p>Init container specs:</p><br><pre><code>      initContainers:<br>      - name: &lt;team&gt;-init      &lt;&lt;&lt;--- replace &lt;team&gt; with team name<br>        image: centos:7<br>        command:<br>        - &quot;bin/bash&quot;<br>        - &quot;-c&quot;<br>        - &quot;echo &lt;team&gt; &gt; /data/&lt;team&gt;.txt&quot;      &lt;&lt;&lt;--- replace &lt;team&gt; with team name<br>        volumeMounts:<br>        - mountPath: /data<br>          name: config-data</code></pre><br><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Task description</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">A pod that begins with &#60;team&#62;-lacey is frequently restarting.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Research the issue to determine what is causing the pod to restart frequently.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Edit the lacey.yaml file to correct the issue.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Verify the deployment successfully deployed.</td></tr></tbody></table><hr><br><p>There must be an init container that creates the missing file.</p><hr><h4 id="diagnosis-9">Diagnosis</h4><p>Checking the running pod for application information.   </p><br><pre><code><br>-- Describe --<br><br>Command:<br><br>    oc describe po team10-lacey-56b79fcdf8-9xrz7<br><br><br><br>Example output:<br><br>    Name:               team10-lacey-56b79fcdf8-9xrz7<br>    Namespace:          team10<br>    Priority:           0<br>    PriorityClassName:  &lt;none&gt;<br>    Node:               pysyd.159.23.66.104.nip.io/159.23.66.104<br>    Start Time:         Sat, 28 Sep 2019 14:55:43 +1000<br>    Labels:             app=team10-lacey<br>                        pod-template-hash=1263597894<br>    Annotations:        openshift.io/scc=restricted<br>    Status:             Running<br>    IP:                 10.129.0.16<br>    Controlled By:      ReplicaSet/team10-lacey-56b79fcdf8<br>    Containers:<br>      team10-lacey:<br>        Container ID:  docker://bef4c14016aaac6120343233cb8e05753636c0478302075f7cad2eca65ddc101<br>        Image:         docker.io/ibmicpcoc/lacey:latest<br>        Image ID:      docker-pullable://docker.io/ibmicpcoc/lacey@sha256:c71f2b2d10a70140bf690dd0cef4834cfcccfece786f8a35de7f71faa608c249<br>        Port:          &lt;none&gt;<br>        Host Port:     &lt;none&gt;<br>        Command:<br>          node<br>          app.js<br>        State:          Waiting<br>          Reason:       CrashLoopBackOff<br>        Last State:     Terminated<br>          Reason:       Error<br>          Exit Code:    1<br>          Started:      Sat, 28 Sep 2019 14:56:19 +1000<br>          Finished:     Sat, 28 Sep 2019 14:56:19 +1000<br>        Ready:          False<br>        Restart Count:  1<br>        Requests:<br>          cpu:     50m<br>          memory:  50Mi<br>        Environment:<br>          APP_NAMESPACE:      team10 (v1:metadata.namespace)<br>          APP_NAME:           team10-lacey-56b79fcdf8-9xrz7 (v1:metadata.name)<br>          COLLECTOR_CONFIG:   &lt;set to the key &#39;COLLECTOR_CONFIG&#39; of config map &#39;team10-collector-config&#39;&gt;   Optional: false<br>          INSTRUCTOR_CONFIG:  &lt;set to the key &#39;INSTRUCTOR_CONFIG&#39; of config map &#39;team10-collector-config&#39;&gt;  Optional: false<br>        Mounts:<br>          /data from config-data (rw)<br>          /var/run/secrets/kubernetes.io/serviceaccount from default-token-kcr98 (ro)<br>    Conditions:<br>      Type              Status<br>      Initialized       True<br>      Ready             False<br>      ContainersReady   False<br>      PodScheduled      True<br>    Volumes:<br>      config-data:<br>        Type:    EmptyDir (a temporary directory that shares a pod&#39;s lifetime)<br>        Medium:<br>      default-token-kcr98:<br>        Type:        Secret (a volume populated by a Secret)<br>        SecretName:  default-token-kcr98<br>        Optional:    false<br>    QoS Class:       Burstable<br>    Node-Selectors:  node-role.kubernetes.io/compute=true<br>    Tolerations:     node.kubernetes.io/memory-pressure:NoSchedule<br>    Events:<br>      Type     Reason     Age                From                                 Message<br>      ----     ------     ----               ----                                 -------<br>      Normal   Scheduled  47s                default-scheduler                    Successfully assigned team10/team10-lacey-56b79fcdf8-9xrz7 to pysyd.159.23.66.104.nip.io<br>      Normal   Pulling    29s (x2 over 42s)  kubelet, pysyd.159.23.66.104.nip.io  pulling image &quot;docker.io/ibmicpcoc/lacey:latest&quot;<br>      Normal   Pulled     11s (x2 over 30s)  kubelet, pysyd.159.23.66.104.nip.io  Successfully pulled image &quot;docker.io/ibmicpcoc/lacey:latest&quot;<br>      Normal   Created    11s (x2 over 30s)  kubelet, pysyd.159.23.66.104.nip.io  Created container<br>      Normal   Started    11s (x2 over 30s)  kubelet, pysyd.159.23.66.104.nip.io  Started container<br>      Warning  BackOff    9s (x2 over 10s)   kubelet, pysyd.159.23.66.104.nip.io  Back-off restarting failed container<br><br><br><br>-- Logs --<br><br>Command:<br><br>    oc logs team10-lacey-56b79fcdf8-9xrz7<br><br><br><br>Example output:<br><br>    9/28/2019, 4:56:39 AM :: lacy001i - Application random key: 64016eb5-bf87-4e94-9b4a-bd13553f2811<br>    9/28/2019, 4:56:39 AM :: lacy003i - Environment APP_NAMESPACE: team10<br>    9/28/2019, 4:56:39 AM :: lacy004i - Environment APP_NAME: Using random key = team10-lacey-56b79fcdf8-9xrz7<br>    9/28/2019, 4:56:39 AM :: lacy013i - Environment COLLECTOR_CONFIG: http://team10-student-ui<br>    9/28/2019, 4:56:39 AM :: lacy014i - Environment INSTRUCTOR_CONFIG: http://dashboard.default<br>    9/28/2019, 4:56:39 AM :: lacy109e - Did not locate config file: /data/team10.txt  Error message: Error: ENOENT: no such file or directory, open &#39;/data/team10.txt&#39;<br><br></code></pre><br><h4 id="problem-discovered-9">Problem discovered</h4><br><p>Log message <strong>lacy109</strong> indicates a missing file. The file must exist before the pod can be started.  The Deployment needs an <strong>initContainers</strong> defined to resolve the issue.</p><h4 id="resolution-9">Resolution</h4><p>An <strong>initContainer</strong> must be added to the Deployment Describe the resolution.  The init container specification is added in the <strong>spec</strong> section at the same level as the <strong>container</strong> definition.  Example:</p><br><pre><code>    spec:<br>      initContainers:<br>      - name: {{team}}-init<br>        image: centos:7<br>        command:<br>        - &quot;bin/bash&quot;<br>        - &quot;-c&quot;<br>        - &quot;echo {{team}} &gt; /data/{{team}}.txt&quot;<br>        volumeMounts:<br>        - mountPath: /data<br>          name: config-data<br>      containers:<br>      - name: {{team}}-lacey<br>        image: {{repoName}}/lacey:latest<br>        imagePullPolicy: Always</code></pre><br><p>Newly running deployment output using <strong>oc describe</strong>.</p><br><p>Checking the running pod for application information.  Review the <strong>Init Containers</strong> section and the additional messages in the <strong>Events</strong> sections.</p><br><pre><code><br>-- Describe --<br><br>Command:<br><br>    oc describe po team10-lacey-56b79fcdf8-9xrz7<br><br><br><br>Example output:<br><br>    Name:               team10-lacey-5b76654dd9-h2lhw<br>    Namespace:          team10<br>    Priority:           0<br>    PriorityClassName:  &lt;none&gt;<br>    Node:               pysyd.159.23.66.108.nip.io/159.23.66.108<br>    Start Time:         Sat, 28 Sep 2019 15:23:12 +1000<br>    Labels:             app=team10-lacey<br>                        pod-template-hash=1632210885<br>    Annotations:        openshift.io/scc=restricted<br>    Status:             Running<br>    IP:                 10.131.0.73<br>    Controlled By:      ReplicaSet/team10-lacey-5b76654dd9<br>    Init Containers:<br>      team10-init:<br>        Container ID:  docker://70317ff8877b015b5ffeb905ab005c2e182f7c111ffa8015be40a2f497e2692a<br>        Image:         centos:7<br>        Image ID:      docker-pullable://docker.io/centos@sha256:307835c385f656ec2e2fec602cf093224173c51119bbebd602c53c3653a3d6eb<br>        Port:          &lt;none&gt;<br>        Host Port:     &lt;none&gt;<br>        Command:<br>          bin/bash<br>          -c<br>          echo team10 &gt; /data/team10.txt<br>        State:          Terminated<br>          Reason:       Completed<br>          Exit Code:    0<br>          Started:      Sat, 28 Sep 2019 15:23:17 +1000<br>          Finished:     Sat, 28 Sep 2019 15:23:17 +1000<br>        Ready:          True<br>        Restart Count:  0<br>        Environment:    &lt;none&gt;<br>        Mounts:<br>          /data from config-data (rw)<br>          /var/run/secrets/kubernetes.io/serviceaccount from default-token-kcr98 (ro)<br>    Containers:<br>      team10-lacey:<br>        Container ID:  docker://8313ad22372c8d58eeaf0a0d77aaaf557854020f8918e95d9bc65517f749153c<br>        Image:         docker.io/ibmicpcoc/lacey:latest<br>        Image ID:      docker-pullable://docker.io/ibmicpcoc/lacey@sha256:c71f2b2d10a70140bf690dd0cef4834cfcccfece786f8a35de7f71faa608c249<br>        Port:          &lt;none&gt;<br>        Host Port:     &lt;none&gt;<br>        Command:<br>          node<br>          app.js<br>        State:          Running<br>          Started:      Sat, 28 Sep 2019 15:23:27 +1000<br>        Ready:          True<br>        Restart Count:  0<br>        Requests:<br>          cpu:     50m<br>          memory:  50Mi<br>        Environment:<br>          APP_NAMESPACE:      team10 (v1:metadata.namespace)<br>          APP_NAME:           team10-lacey-5b76654dd9-h2lhw (v1:metadata.name)<br>          COLLECTOR_CONFIG:   &lt;set to the key &#39;COLLECTOR_CONFIG&#39; of config map &#39;team10-collector-config&#39;&gt;   Optional: false<br>          INSTRUCTOR_CONFIG:  &lt;set to the key &#39;INSTRUCTOR_CONFIG&#39; of config map &#39;team10-collector-config&#39;&gt;  Optional: false<br>        Mounts:<br>          /data from config-data (rw)<br>          /var/run/secrets/kubernetes.io/serviceaccount from default-token-kcr98 (ro)<br>    Conditions:<br>      Type              Status<br>      Initialized       True<br>      Ready             True<br>      ContainersReady   True<br>      PodScheduled      True<br>    Volumes:<br>      config-data:<br>        Type:    EmptyDir (a temporary directory that shares a pod&#39;s lifetime)<br>        Medium:<br>      default-token-kcr98:<br>        Type:        Secret (a volume populated by a Secret)<br>        SecretName:  default-token-kcr98<br>        Optional:    false<br>    QoS Class:       Burstable<br>    Node-Selectors:  node-role.kubernetes.io/compute=true<br>    Tolerations:     node.kubernetes.io/memory-pressure:NoSchedule<br>    Events:<br>      Type    Reason     Age   From                                 Message<br>      ----    ------     ----  ----                                 -------<br>      Normal  Scheduled  1m    default-scheduler                    Successfully assigned team10/team10-lacey-5b76654dd9-h2lhw to pysyd.159.23.66.108.nip.io<br>      Normal  Pulled     1m    kubelet, pysyd.159.23.66.108.nip.io  Container image &quot;centos:7&quot; already present on machine<br>      Normal  Created    1m    kubelet, pysyd.159.23.66.108.nip.io  Created container<br>      Normal  Started    1m    kubelet, pysyd.159.23.66.108.nip.io  Started container<br>      Normal  Pulling    1m    kubelet, pysyd.159.23.66.108.nip.io  pulling image &quot;docker.io/ibmicpcoc/lacey:latest&quot;<br>      Normal  Pulled     1m    kubelet, pysyd.159.23.66.108.nip.io  Successfully pulled image &quot;docker.io/ibmicpcoc/lacey:latest&quot;<br>      Normal  Created    1m    kubelet, pysyd.159.23.66.108.nip.io  Created container<br>      Normal  Started    1m    kubelet, pysyd.159.23.66.108.nip.io  Started container<br><br></code></pre><br><hr><br><hr><br><p>All references to &#60;team&#62; should be replaced with your team name.</p><h4 id="resources-10">Resources</h4><ul><li>K8 yaml    - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/magma.yaml" target="_blank">magma.yaml</a></li><li>Dockerfile - <a href="https://github.com/IBM-ICP-CoC/PyRK8s-Wave2/blob/master/magma_Dockerfile" target="_blank">Dockerfile</a></li></ul><h4 id="useful-information-10">Useful information</h4><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Item</th><th align="left">Value</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">cpu:</td><td align="left">50m</td></tr><tr style="background-color: #f8f8f8;"><td align="left">memory:</td><td align="left">50Mi</td></tr><tr style="background-color: #f8f8f8;"><td align="left">image:</td><td align="left">ibmicpcoc/magma:latest</td></tr><tr style="background-color: #f8f8f8;"><td align="left">ports</td><td align="left">none</td></tr><tr style="background-color: #f8f8f8;"><td align="left">YAML</td><td align="left">command: [&quot;node&quot;, &quot;app.js&quot;]</td></tr></tbody></table><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Secret Parameter</th><th align="left">Value</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">Name</td><td align="left">&#60;team&#62;-secret-file</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Content</td><td align="left">Base64 encoded: debug me</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Type</td><td align="left">Opaque</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Mount</td><td align="left">/var/config</td></tr><tr style="background-color: #f8f8f8;"><td align="left">File</td><td align="left">secret.txt</td></tr></tbody></table><p><strong>Note</strong> that the value of the parameter &#39;Content&#39; must be base64 encoded.  </p><br><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">ConfigMap Parameter</th><th align="left">Value</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">Name</td><td align="left">&#60;team&#62;-configmap-file</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Content</td><td align="left">debug</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Mount</td><td align="left">/var/secret</td></tr><tr style="background-color: #f8f8f8;"><td align="left">File</td><td align="left">config.txt</td></tr></tbody></table><br><br><table class="table-bordered" cellspacing="10"><thead style="background-color: #eee;"><tr style="background-color: #f8f8f8;"><th align="left">Task description</th></tr></thead><tbody><tr style="background-color: #f8f8f8;"><td align="left">A pod that begins with &#60;team&#62;-magma has a status of ContainerCreating.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Research the issue to determine what is causing the pod to be in this status.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Describe the pod to assist in determining why this issue is occurring.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Edit the magma.yaml file to correct the issue using provided <strong>Useful Information</strong>.</td></tr><tr style="background-color: #f8f8f8;"><td align="left">Verify the deployment successfully deployed by viewing log message <strong>magm115i</strong></td></tr></tbody></table><hr><br><p>Create the secret and configmap resources in the Deployment yaml.</p><p>Examples of the base64 command:   </p><br><pre><code><br>Encode:<br><br>    echo -n &quot;debug me&quot; | base64     &lt;&lt;&lt;--- be sure to include the -n <br>    ZGVidWcgbWU=   <br><br><br>Decode:<br><br>    echo &quot;ZGVidWcgbWU=&quot; | base64 --decode   <br>    debug me   <br></code></pre><br><hr><br><h4 id="diagnosis-10">Diagnosis</h4><p>Checking the running pod for information.   </p><br><pre><code><br>NOTE: Use oc get po to get pod name<br><br><br>-- Describe --<br><br>Command: <br><br>    oc describe po team10-magma-54644c86d-5zb25<br><br><br><br>Example output:    <br><br>    Name:               team10-magma-54644c86d-5zb25<br>    Namespace:          team10<br>    Priority:           0<br>    PriorityClassName:  &lt;none&gt;<br>    Node:               pysyd.159.23.66.101.nip.io/<br>    Labels:             app=team10-magma<br>                        pod-template-hash=102007428<br>    Annotations:        openshift.io/scc=restricted<br>    Status:             Pending<br>    IP:<br>    Controlled By:      ReplicaSet/team10-magma-54644c86d<br>    Containers:<br>      team10-magma:<br>        Image:      docker.io/ibmicpcoc/magma:latest<br>        Port:       &lt;none&gt;<br>        Host Port:  &lt;none&gt;<br>        Command:<br>          node<br>          app.js<br>        Requests:<br>          cpu:     50m<br>          memory:  50Mi<br>        Environment:<br>          APP_NAMESPACE:      team10 (v1:metadata.namespace)<br>          APP_NAME:           team10-magma-54644c86d-5zb25 (v1:metadata.name)<br>          COLLECTOR_CONFIG:   &lt;set to the key &#39;COLLECTOR_CONFIG&#39; of config map &#39;team10-collector-config&#39;&gt;   Optional: false<br>          INSTRUCTOR_CONFIG:  &lt;set to the key &#39;INSTRUCTOR_CONFIG&#39; of config map &#39;team10-collector-config&#39;&gt;  Optional: false<br>        Mounts:<br>          /var/config from configvol (rw)<br>          /var/run/secrets/kubernetes.io/serviceaccount from default-token-kcr98 (ro)<br>          /var/secret from secretvol (rw)<br>    Conditions:<br>      Type           Status<br>      PodScheduled   True<br>    Volumes:<br>      configvol:<br>        Type:      ConfigMap (a volume populated by a ConfigMap)<br>        Name:      team10-configmap-file<br>        Optional:  false<br>      secretvol:<br>        Type:        Secret (a volume populated by a Secret)<br>        SecretName:  team10-secret-file<br>        Optional:    false<br>      default-token-kcr98:<br>        Type:        Secret (a volume populated by a Secret)<br>        SecretName:  default-token-kcr98<br>        Optional:    false<br>    QoS Class:       Burstable<br>    Node-Selectors:  node-role.kubernetes.io/compute=true<br>    Tolerations:     node.kubernetes.io/memory-pressure:NoSchedule<br>    Events:<br>      Type     Reason       Age               From                                 Message<br>      ----     ------       ----              ----                                 -------<br>      Normal   Scheduled    19s               default-scheduler                    Successfully assigned team10/team10-magma-54644c86d-5zb25 to pysyd.159.23.66.101.nip.io<br>      Warning  FailedMount  3s (x4 over 16s)  kubelet, pysyd.159.23.66.101.nip.io  MountVolume.SetUp failed for volume &quot;configvol&quot; : configmaps &quot;team10-configmap-file&quot; not found<br>      Warning  FailedMount  2s (x4 over 16s)  kubelet, pysyd.159.23.66.101.nip.io  MountVolume.SetUp failed for volume &quot;secretvol&quot; : secrets &quot;team10-secret-file&quot; not found<br><br></code></pre><br><h4 id="problem-discovered-10">Problem discovered</h4><br><p>Two volume mounts, configvol and secretvol, are failing.  These mounts require a configmap and secret resource definitions that are not found.</p><h4 id="resolution-10">Resolution</h4><p>In the Deployment yaml add definitions for the secret and configmap resources using the data provided in the <strong>Useful Information</strong> section.</p><br><pre><code><br>Example secret:<br><br>---<br>--- # Secret<br>---<br>apiVersion: v1<br>kind: Secret<br>metadata:<br>  name: &lt;team&gt;-secret-file      &lt;&lt;&lt;--- replace &lt;team&gt; with team name<br>  namespace: &lt;team&gt;             &lt;&lt;&lt;--- replace &lt;team&gt; with team name<br>type: Opaque<br>data:<br>  secret.txt: &lt;base64 encoded value for debug me&gt;<br><br><br><br>Example configmap:<br>---<br>--- # Configmap<br>---<br>kind: ConfigMap<br>apiVersion: v1<br>metadata:<br>  name: &lt;team&gt;-secret-file      &lt;&lt;&lt;--- replace &lt;team&gt; with team name<br>  namespace: &lt;team&gt;             &lt;&lt;&lt;--- replace &lt;team&gt; with team name<br>data:<br>  config.txt:  debug<br></code></pre><br><br><br><p>Log message &quot;<strong>magm115i - All OK</strong>&quot; indicates the pod has successfully deployed and running.</p><br><pre><code><br>-- Logs --<br><br>Command:<br><br>    oc logs team10-magma-54644c86d-74jqs<br><br><br><br>Example output:<br><br>    9/28/2019, 5:59:34 AM :: magm001i - Application random key: 409c2512-0680-4071-93c4-23e5b0f25220<br>    9/28/2019, 5:59:34 AM :: magm003i - Environment APP_NAMESPACE: team10<br>    9/28/2019, 5:59:34 AM :: magm004i - Environment APP_NAME: Using random key = team10-magma-54644c86d-74jqs<br>    9/28/2019, 5:59:34 AM :: magm013i - Environment COLLECTOR_CONFIG: http://team10-student-ui<br>    9/28/2019, 5:59:34 AM :: magm014i - Environment INSTRUCTOR_CONFIG: http://dashboard.default<br>    9/28/2019, 5:59:34 AM :: magm115i - All OK<br>    9/28/2019, 5:59:34 AM :: magm011i - Initial reporting to student<br>    9/28/2019, 5:59:34 AM :: magm012i - Initial reporting to instructor<br><br></code></pre><br></body><br>